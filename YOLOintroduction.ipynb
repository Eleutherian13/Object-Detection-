{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44940f75",
   "metadata": {},
   "source": [
    "# YOLO Object Detection Introduction\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates object detection using YOLOv8 and YOLOv11 pre-trained models from Ultralytics.\n",
    "YOLO (You Only Look Once) is a real-time object detection algorithm that can identify and localize multiple objects in images and videos.\n",
    "\n",
    "## Contents\n",
    "1. **Installation & Setup** - Installing Ultralytics library and verifying the environment\n",
    "2. **Command-line Inference** - Using YOLO command-line tools for quick predictions\n",
    "3. **Python-based Inference** - Using the Python API for more control and flexibility\n",
    "4. **Results Analysis** - Extracting and interpreting detection results (bounding boxes, confidence scores, class names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: ultralytics in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (8.4.6)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (12.0.0)\n",
      "Requirement already satisfied: torch!=2.4.0,>=1.8.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (2.9.1)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (1.37.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (7.1.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (3.10.8)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from ultralytics) (4.13.0.90)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.37.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from polars>=0.20.0->ultralytics) (1.37.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.6.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (2026.1.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from sympy>=1.13.3->torch!=2.4.0,>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manas\\onedrive\\desktop\\dl campusx\\venv\\lib\\site-packages (from jinja2->torch!=2.4.0,>=1.8.0->ultralytics) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install Ultralytics library - provides YOLO models and utilities\n",
    "# This library includes pre-trained YOLOv8 and YOLOv11 models\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82133f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.6  Python-3.10.8 torch-2.9.1+cpu CPU (13th Gen Intel Core i7-13700HX)\n",
      "Setup complete  (24 CPUs, 15.7 GB RAM, 325.5/475.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Verify the Ultralytics installation and check system compatibility\n",
    "import ultralytics \n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b16fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "def show_img(img):\n",
    "    \"\"\"\n",
    "    Display an image using OpenCV.\n",
    "    \n",
    "    Args:\n",
    "        img (str): Path to the image file to display\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Raises:\n",
    "        Prints error message if image file is not found\n",
    "    \"\"\"\n",
    "    image = cv2.imread(img)\n",
    "    if image is None:\n",
    "        print(\"Error: Image not found at the specified path\")\n",
    "        return \n",
    "    cv2.imshow(\"image\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a1241",
   "metadata": {},
   "source": [
    "## Inference with YOLOv11 Pre-trained Model\n",
    "\n",
    "### Method 1: Command-line Interface\n",
    "Using the `yolo` command directly from the terminal for quick predictions.\n",
    "This approach downloads the image from a public source and runs inference with the YOLOv11 small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af6a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 1% ──────────── 226.3KB/18.4MB 2.1MB/s 0.1s<8.5s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 7% ╸─────────── 1.3/18.4MB 11.2MB/s 0.2s<1.5s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 16% ━╸────────── 2.9/18.4MB 15.6MB/s 0.3s<1.0s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 24% ━━╸───────── 4.5/18.4MB 15.1MB/s 0.4s<0.9s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 30% ━━━╸──────── 5.5/18.4MB 10.0MB/s 0.5s<1.3s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 35% ━━━━──────── 6.4/18.4MB 8.6MB/s 0.6s<1.4s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 39% ━━━━╸─────── 7.2/18.4MB 7.7MB/s 0.7s<1.4s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 41% ━━━━╸─────── 7.6/18.4MB 2.0MB/s 0.9s<5.4s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 53% ━━━━━━────── 9.9/18.4MB 18.1MB/s 1.0s<0.5s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 60% ━━━━━━━───── 11.1/18.4MB 12.5MB/s 1.1s<0.6s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 65% ━━━━━━━╸──── 12.0/18.4MB 8.8MB/s 1.2s<0.7s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 70% ━━━━━━━━──── 12.9/18.4MB 8.4MB/s 1.4s<0.7s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 75% ━━━━━━━━╸─── 13.8/18.4MB 9.2MB/s 1.5s<0.5s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 79% ━━━━━━━━━╸── 14.6/18.4MB 8.4MB/s 1.6s<0.4s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 84% ━━━━━━━━━━── 15.6/18.4MB 9.1MB/s 1.7s<0.3s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 89% ━━━━━━━━━━╸─ 16.5/18.4MB 9.0MB/s 1.8s<0.2s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 92% ━━━━━━━━━━━─ 16.9/18.4MB 3.7MB/s 1.9s<0.4s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 92% ━━━━━━━━━━━─ 17.0/18.4MB 50.8KB/s 2.1s<29.0s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 93% ━━━━━━━━━━━─ 17.1/18.4MB 183.6KB/s 2.3s<7.6s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 93% ━━━━━━━━━━━─ 17.1/18.4MB 234.1KB/s 2.4s<5.8s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11s.pt to 'yolo11s.pt': 100% ━━━━━━━━━━━━ 18.4MB 7.5MB/s 2.5s\n",
      "Ultralytics 8.4.6  Python-3.10.8 torch-2.9.1+cpu CPU (13th Gen Intel Core i7-13700HX)\n",
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
      "\n",
      "WARNING Download failure, retrying 1/3 https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg... HTTP Error 403: Forbidden\n",
      "image 1/1 c:\\Users\\manas\\OneDrive\\Desktop\\DL CampusX\\DeepLearning\\CNN's\\module3\\pexels-photo-13872248.jpeg: 448x640 6 persons, 196.7ms\n",
      "Speed: 83.6ms preprocess, 196.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\manas\\OneDrive\\Desktop\\DL CampusX\\DeepLearning\\CNN's\\module3\\runs\\detect\\predict\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "#=#=#                                                                          \n",
      "###                                                                        4.5%\n",
      "#################                                                         23.9%\n",
      "########################################################                  78.7%\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image using YOLOv11 small model\n",
    "# model: yolo11s.pt - pre-trained YOLOv11 small model\n",
    "# source: image URL - the image to perform detection on\n",
    "# The results are automatically saved to runs/detect/predict/\n",
    "!yolo predict model=yolo11s.pt source=\"https://images.pexels.com/photos/13872248/pexels-photo-13872248.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the downloaded image\n",
    "img = show_img(\"pexels-photo-13872248.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f702ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Python API\n",
    "# This approach gives us more control over the inference process and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8caf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 3.2MB/s 1.9s.9s<0.0s.8ss\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 nano pre-trained model\n",
    "# 'yolov8n.pt' - nano version (smallest and fastest, less accurate)\n",
    "# Other options: yolov8s, yolov8m, yolov8l, yolov8x (increasing size and accuracy)\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d50c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 'source' is missing. Using 'source=C:\\Users\\manas\\OneDrive\\Desktop\\DL CampusX\\venv\\Lib\\site-packages\\ultralytics\\assets'.\n",
      "\n",
      "image 1/2 C:\\Users\\manas\\OneDrive\\Desktop\\DL CampusX\\venv\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 161.3ms\n",
      "image 2/2 C:\\Users\\manas\\OneDrive\\Desktop\\DL CampusX\\venv\\Lib\\site-packages\\ultralytics\\assets\\zidane.jpg: 384x640 2 persons, 1 tie, 284.4ms\n",
      "Speed: 5.4ms preprocess, 222.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference on the image\n",
    "# Returns a list of Results objects containing detection information\n",
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45070258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display detection results\n",
    "# Including bounding boxes in different formats, confidence scores, and class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8712fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box (xywh)\n",
      "tensor([[413.9370, 494.0589, 782.1314, 525.5631]])\n",
      "  Normalized Bounding Boxes (xywhn):\n",
      "tensor([[0.5110, 0.4575, 0.9656, 0.4866]])\n",
      "  Bounding Boxes (xyxy):\n",
      "tensor([[ 22.8713, 231.2773, 805.0027, 756.8405]])\n",
      "  Normalized Bounding Boxes (xyxyn):\n",
      "tensor([[0.0282, 0.2141, 0.9938, 0.7008]])\n",
      "  Class Names:\n",
      "['bus']\n",
      "  Confidence Scores:\n",
      "tensor([0.8734])\n",
      "Bounding box (xywh)\n",
      "tensor([[614.6694, 454.6507, 999.5990, 514.4774]])\n",
      "  Normalized Bounding Boxes (xywhn):\n",
      "tensor([[0.4802, 0.6315, 0.7809, 0.7146]])\n",
      "  Bounding Boxes (xyxy):\n",
      "tensor([[ 114.8699,  197.4120, 1114.4689,  711.8894]])\n",
      "  Normalized Bounding Boxes (xyxyn):\n",
      "tensor([[0.0897, 0.2742, 0.8707, 0.9887]])\n",
      "  Class Names:\n",
      "['person']\n",
      "  Confidence Scores:\n",
      "tensor([0.8360])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate through detection results and extract bounding box information\n",
    "for i, result in enumerate(results):\n",
    "    # Get first detection in the first result (assuming single image input)\n",
    "    boxes = result.boxes[0]\n",
    "    \n",
    "    # XYWH format: center coordinates (x, y) and width, height\n",
    "    xywh = boxes.xywh\n",
    "    print(\"Bounding Box (XYWH - center x, center y, width, height):\")\n",
    "    print(xywh)\n",
    "\n",
    "    # XYWHN format: normalized XYWH (0-1 scale, useful for comparing across different image sizes)\n",
    "    xywhn = boxes.xywhn\n",
    "    print(\"\\nNormalized Bounding Box (XYWHN - 0-1 scale):\")\n",
    "    print(xywhn)\n",
    "\n",
    "    # XYXY format: top-left corner (x1, y1) and bottom-right corner (x2, y2)\n",
    "    # This is the most common format for visualization and further processing\n",
    "    xyxy = boxes.xyxy\n",
    "    print(\"\\nBounding Box (XYXY - top-left x1, y1, bottom-right x2, y2):\")\n",
    "    print(xyxy)\n",
    "\n",
    "    # XYXYN format: normalized XYXY coordinates (0-1 scale)\n",
    "    xyxyn = boxes.xyxyn\n",
    "    print(\"\\nNormalized Bounding Box (XYXYN - 0-1 scale):\")\n",
    "    print(xyxyn)\n",
    "\n",
    "    # Extract class names for each detection\n",
    "    # Maps class indices to human-readable class names\n",
    "    class_names = [result.names[int(cls)] for cls in boxes.cls]\n",
    "    print(\"\\nDetected Object Classes:\")\n",
    "    print(class_names)\n",
    "\n",
    "    # Confidence scores for each detection (0-1, higher = more confident)\n",
    "    confidence_scores = boxes.conf\n",
    "    print(\"\\nConfidence Scores:\")\n",
    "    print(confidence_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb1981",
   "metadata": {},
   "source": [
    "## Summary of Bounding Box Formats\n",
    "\n",
    "| Format | Description | Example Use |\n",
    "|--------|-------------|-------------|\n",
    "| **XYWH** | Center coordinates + dimensions (not normalized) | Display on original image |\n",
    "| **XYWHN** | XYWH normalized to 0-1 scale | Scale-independent comparisons |\n",
    "| **XYXY** | Top-left and bottom-right corners | Cropping, visualization |\n",
    "| **XYXYN** | XYXY normalized to 0-1 scale | Standardized format across images |\n",
    "\n",
    "## Key Takeaways\n",
    "- **YOLOv8n** provides fast inference with good accuracy for real-time applications\n",
    "- **Multiple bounding box formats** allow flexibility in downstream tasks\n",
    "- **Confidence scores** indicate prediction reliability (filter low confidence detections as needed)\n",
    "- Results can be used for object tracking, cropping, or further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
